{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/graph_var')\n",
    "\n",
    "from graph_var.graph_var.utils import load_graph_from_pkl, read_gfa_line_by_line, node_complement\n",
    "from graph_var.graph_var.graph import PangenomeGraph\n",
    "from graph_var.graph_var.evaluating_functions import *\n",
    "import pandas as pd\n",
    "\n",
    "version = 'v1'\n",
    "\n",
    "graph_obj_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Graph_objs_{version}\"\n",
    "raw_vcf_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/VCFs_chr\"\n",
    "graph_vcf_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/VCFs_{version}\"\n",
    "\n",
    "ref_tree_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Data/reference_tree_gfa_{version}\"\n",
    "gfa_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Data/chromosome_gfa_{version}\"\n",
    "snarl_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Data/chr_snarls_{version}\"\n",
    "bubble_summary_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Bubble_summary_{version}\"\n",
    "\n",
    "var_summary_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Stats_chr_{version}\"\n",
    "data_vis_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Data_visualization_{version}\"\n",
    "\n",
    "region_dir = f\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Region_files\"\n",
    "\n",
    "mode = 'AT'\n",
    "wavevcf = True\n",
    "exclude_terminus = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_list = list(range(1,23))\n",
    "# chr_list = [22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNP count in HLA-A large insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1740551it [00:31, 55135.61it/s]\n"
     ]
    }
   ],
   "source": [
    "hla_insertion = (\"61637118\", \"61637368\")\n",
    "\n",
    "chr6_AT = pd.read_csv(f\"{bubble_summary_dir}/bubble_variant_counts_chr6_AT.tsv\", sep='\\t')\n",
    "hla_insertion_var = eval(chr6_AT[chr6_AT['Bubble'] == str(hla_insertion)]['Within'].iloc[0])\n",
    "\n",
    "chr6_var_dict = {}\n",
    "\n",
    "for row in tqdm(read_vcf_line_by_line(f\"{graph_vcf_dir}/graph_chr6_no_terminus.vcf\")):\n",
    "    ID = extract_bubble_ids(row['ID'], symbol=True)\n",
    "    if ID not in hla_insertion_var:\n",
    "        continue\n",
    "    chr6_var_dict[ID] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp = 0\n",
    "offlinear_snp = 0\n",
    "\n",
    "for id, data in chr6_var_dict.items():\n",
    "    info =  get_info_dict(data['INFO'])\n",
    "    if info['VT'] == 'SNP':\n",
    "        snp += 1\n",
    "        if int(info['DR'].split(',')[1]) != 0:\n",
    "            offlinear_snp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 62)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp, offlinear_snp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the max length of node in chr22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr22_graph = load_graph_from_pkl(f\"{graph_obj_dir}/chr22.pkl.gz\", compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500493 1484\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "count = 0\n",
    "for node, data in chr22_graph.nodes(data=True):\n",
    "    length =  len(data['sequence'])\n",
    "    if length > max_len:\n",
    "        max_len = length\n",
    "    if length > 1024:\n",
    "        count += 1\n",
    "print(max_len, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the reason of two rawvcf only SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_walks(gfa_path):\n",
    "    walk_list = []\n",
    "    for parts in read_gfa_line_by_line(gfa_path):\n",
    "        if parts[0] != 'W':\n",
    "            continue\n",
    "        sample_name = parts[2]\n",
    "        walk = parts[3]\n",
    "        walk_list.append((sample_name, walk))\n",
    "    return walk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr6_graph = load_graph_from_pkl(f\"{graph_obj_dir}/chr6.pkl.gz\", compressed=True)\n",
    "chr7_graph = load_graph_from_pkl(f\"{graph_obj_dir}/chr7.pkl.gz\", compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_nodes = ['61846503_+', '61846504_+', '61846505_-', '61846506_-', '61846507_+']\n",
    "example2_nodes = ['67791427_+', '67791428_+', '67791429_-', '67791430_-', '67791431_+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr6_walks = get_walks(f\"{gfa_dir}/chr6.gfa\")\n",
    "chr7_walks = get_walks(f\"{gfa_dir}/chr7.gfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive subgraph:\n",
      "61846503_+ ['61846506_-', '61846504_+'] ['61846501_+', '61846502_-']\n",
      "61846504_+ ['61846507_+', '61846505_-'] ['61846503_+']\n",
      "61846505_- ['61846506_-'] ['61846504_+']\n",
      "61846506_- ['61846507_+', '-_terminus_+'] ['61846503_+', '61846505_-']\n",
      "61846507_+ ['61846508_+', '61846509_-'] ['61846504_+', '61846506_-']\n",
      "Negative subgraph:\n",
      "61846507_- ['61846504_-', '61846506_+'] ['61846508_-', '61846509_+']\n",
      "61846506_+ ['61846503_-', '61846505_+'] ['61846507_-', '-_terminus_-']\n",
      "61846505_+ ['61846504_-'] ['61846506_+']\n",
      "61846504_- ['61846503_-'] ['61846507_-', '61846505_+']\n",
      "61846503_- ['61846501_-', '61846502_+'] ['61846506_+', '61846504_-']\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive subgraph:\")\n",
    "for node in example1_nodes:\n",
    "    print(node, list(chr6_graph.neighbors(node)), list(chr6_graph.predecessors(node)))\n",
    "print(\"Negative subgraph:\")\n",
    "for node in example1_nodes[::-1]:\n",
    "    node = node_complement(node)\n",
    "    print(node, list(chr6_graph.neighbors(node)), list(chr6_graph.predecessors(node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positive_paths = set()\n",
    "unique_negative_paths = set()\n",
    "for sample, walk in chr6_walks:\n",
    "    pos_start = example1_nodes[0]\n",
    "    neg_start = node_complement(example1_nodes[-1])\n",
    "    if pos_start in set(walk):\n",
    "        start_idx_pos = walk.index(pos_start)\n",
    "        unique_positive_paths.add('|'.join(walk[start_idx_pos:start_idx_pos+5]))\n",
    "    if neg_start in set(walk):\n",
    "        start_idx_neg = walk.index(neg_start)\n",
    "        unique_negative_paths.add('|'.join(walk[start_idx_neg:start_idx_neg+5]))\n",
    "    if walk[0] == \"61846506_+\":\n",
    "        unique_negative_paths.add('|'.join(walk[:5]))\n",
    "    if walk[-1] == \"61846506_-\":\n",
    "        unique_positive_paths.add('|'.join(walk[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'61846503_+|61846504_+|61846507_+|61846508_+|61846510_+',\n",
       "  '61846503_+|61846506_-|61846507_+|61846508_+|61846510_+'},\n",
       " {'61846506_+|61846505_+|61846504_-|61846503_-|61846501_-',\n",
       "  '61846507_-|61846504_-|61846503_-|61846501_-|61846500_-',\n",
       "  '61846507_-|61846506_+|61846503_-|61846502_+|61846500_-'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_positive_paths, unique_negative_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive subgraph:\n",
      "67791427_+ ['67791428_+', '67791430_-'] ['67791425_+', '67791426_-']\n",
      "67791428_+ ['67791431_+', '67791429_-'] ['67791427_+', '+_terminus_+']\n",
      "67791429_- ['67791430_-'] ['67791428_+']\n",
      "67791430_- ['67791431_+'] ['67791427_+', '67791429_-']\n",
      "67791431_+ ['67791432_+', '67791433_-'] ['67791428_+', '67791430_-']\n",
      "Negative subgraph:\n",
      "67791431_- ['67791428_-', '67791430_+'] ['67791432_-', '67791433_+']\n",
      "67791430_+ ['67791427_-', '67791429_+'] ['67791431_-']\n",
      "67791429_+ ['67791428_-'] ['67791430_+']\n",
      "67791428_- ['67791427_-', '+_terminus_-'] ['67791431_-', '67791429_+']\n",
      "67791427_- ['67791425_-', '67791426_+'] ['67791428_-', '67791430_+']\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive subgraph:\")\n",
    "for node in example2_nodes:\n",
    "    print(node, list(chr7_graph.neighbors(node)), list(chr7_graph.predecessors(node)))\n",
    "print(\"Negative subgraph:\")\n",
    "for node in example2_nodes[::-1]:\n",
    "    node = node_complement(node)\n",
    "    print(node, list(chr7_graph.neighbors(node)), list(chr7_graph.predecessors(node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positive_paths = set()\n",
    "unique_negative_paths = set()\n",
    "for sample, walk in chr7_walks:\n",
    "    pos_start = example2_nodes[0]\n",
    "    neg_start = node_complement(example2_nodes[-1])\n",
    "    if pos_start in set(walk):\n",
    "        start_idx_pos = walk.index(pos_start)\n",
    "        unique_positive_paths.add('|'.join(walk[start_idx_pos:start_idx_pos+5]))\n",
    "    if neg_start in set(walk):\n",
    "        start_idx_neg = walk.index(neg_start)\n",
    "        unique_negative_paths.add('|'.join(walk[start_idx_neg:start_idx_neg+5]))\n",
    "    if walk[0] == \"67791428_+\":\n",
    "        unique_positive_paths.add('|'.join(walk[:5]))\n",
    "    if walk[-1] == \"67791428_-\":\n",
    "        unique_negative_paths.add('|'.join(walk[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'67791427_+|67791428_+|67791431_+|67791432_+|67791434_+',\n",
       "  '67791427_+|67791428_+|67791431_+|67791433_-|67791434_+',\n",
       "  '67791427_+|67791430_-|67791431_+|67791432_+|67791434_+'},\n",
       " {'67791431_-|67791428_-|67791427_-|67791425_-|67791424_-',\n",
       "  '67791431_-|67791430_+|67791427_-|67791425_-|67791424_-',\n",
       "  '67791431_-|67791430_+|67791427_-|67791426_+|67791424_-',\n",
       "  '67791431_-|67791430_+|67791429_+|67791428_-',\n",
       "  '67791432_-|67791431_-|67791430_+|67791429_+|67791428_-'})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_positive_paths, unique_negative_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample, walk in chr7_walks:\n",
    "    if len(walk) < 10:\n",
    "        print(walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of non-GRCh38 sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [51:03<00:00, 139.23s/it] \n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "\n",
    "total_length_linear = 0\n",
    "total_length_offlinear = 0\n",
    "\n",
    "for i in tqdm(chr_list):\n",
    "    G = load_graph_from_pkl(f\"{graph_obj_dir}/chr{i}.pkl.gz\", compressed=True)\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if data['direction'] == 1 and data['on_reference_path'] == 1:\n",
    "            total_length_linear += len(data['sequence'])\n",
    "        if data['direction'] == 1 and data['on_reference_path'] == 0:\n",
    "            total_length_offlinear += len(data['sequence'])\n",
    "        total_length += len(data['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6008516378, 2875001522, 129256667)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_length, total_length_linear, total_length_offlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6008516378"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_length_linear + total_length_offlinear) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of nodes, edges, walks for the whole gfa graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 0\n",
    "num_edges = 0\n",
    "hap_walk_dicts = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parts in read_gfa_line_by_line(\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Data/entire_gfa/hprc-v1.1-mc-grch38.gfa.gz\", compressed=True):\n",
    "    if parts[0] == 'S':\n",
    "        binode, sequence = parts[1], parts[2]\n",
    "        num_nodes += 1\n",
    "    elif parts[0] == 'L':\n",
    "        biedge = parts[1]\n",
    "        node1 = biedge[0] + '_' + biedge[2]\n",
    "        node2 = biedge[1] + '_' + biedge[3]\n",
    "        num_edges += 1\n",
    "    elif parts[0] == 'W':\n",
    "        hit_reference = parts[1]\n",
    "        sample_name = parts[2]\n",
    "        walk = parts[3]\n",
    "\n",
    "        hap_walk_dicts[sample_name] = hap_walk_dicts.get(sample_name, 0) + 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80069733 110938345 90 113 566 286.3333333333333\n"
     ]
    }
   ],
   "source": [
    "print(num_nodes, num_edges, \n",
    "      len(hap_walk_dicts), \n",
    "      min(hap_walk_dicts.values()), \n",
    "      max(hap_walk_dicts.values()),\n",
    "      sum(hap_walk_dicts.values())/len(hap_walk_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INDEL count comparison (Pantree VCF, Raw VCF, Wave VCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursion_dict():\n",
    "    return defaultdict(recursion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:50<00:00, 50.38s/it]\n"
     ]
    }
   ],
   "source": [
    "indel_count_per_sample = recursion_dict()\n",
    "sample_list = None\n",
    "entry_counts = [0,0,0]\n",
    "\n",
    "for chr in tqdm(chr_list):\n",
    "    graph_vcf_path = f\"{graph_vcf_dir}/graph_chr{chr}{'_no_terminus' if exclude_terminus else ''}.vcf\"\n",
    "    rawvcf_path = f\"{raw_vcf_dir}/hprc-v1.1-mc-grch38.raw_chr{chr}.vcf\"\n",
    "    vcfwave_path = f\"{raw_vcf_dir}/hprc-v1.1-mc-grch38.vcfbub.a100k.wave_chr{chr}.vcf\"\n",
    "\n",
    "    for row in read_vcf_line_by_line(graph_vcf_path):\n",
    "        samples = list(row.keys())[9:]\n",
    "\n",
    "        info_dict = get_info_dict(row['INFO'])\n",
    "        VT = info_dict['VT']\n",
    "        ref = row['REF'] if row['REF'] != '.' else info_dict['NR']\n",
    "        alt = row['ALT']\n",
    "        length = (len(ref) if ref != '.' else 0) + (len(alt) if alt != '.' else 0)\n",
    "\n",
    "        linear = int(info_dict['DR'].split(',')[1]) == 0\n",
    "\n",
    "        if VT not in {'INS', 'DEL'} or length < 50 or not linear:\n",
    "            continue\n",
    "        entry_counts[0] += 1\n",
    "        for sample in samples:\n",
    "            entry = row[sample]\n",
    "            gt = entry.split(':')[0]\n",
    "            count = len({idx for idx in gt.split('|') if idx not in {'.', '0'}})\n",
    "            assert count <= 2\n",
    "            if 'pantree' in indel_count_per_sample and sample in indel_count_per_sample['pantree']:\n",
    "                indel_count_per_sample['pantree'][sample] += count\n",
    "            else:\n",
    "                indel_count_per_sample['pantree'][sample] = count\n",
    "    \n",
    "    for row in read_vcf_line_by_line(rawvcf_path):\n",
    "        samples = list(row.keys())[9:]\n",
    "\n",
    "        if sample_list is None:\n",
    "            sample_list = samples\n",
    "\n",
    "        ref = row['REF']\n",
    "        alts = row['ALT'].split(',')\n",
    "\n",
    "        for idx, alt in enumerate(alts):\n",
    "            length = len(ref) + len(alt)\n",
    "\n",
    "            IND = False\n",
    "            if (len(ref) <= 1 and len(alt) > 1) or (len(alt) <= 1 and len(ref) > 1):\n",
    "                IND = True\n",
    "\n",
    "            if not IND or length < 50:\n",
    "                continue\n",
    "            entry_counts[1] += 1\n",
    "            for sample in samples:\n",
    "                entry = row[sample]\n",
    "                gt = entry.split(':')[0]\n",
    "                count = len({idx for idx in gt.split('|') if idx not in {'.', '0'}})\n",
    "                assert count <= 2\n",
    "                if 'rawvcf' in indel_count_per_sample and sample in indel_count_per_sample['rawvcf']:\n",
    "                    indel_count_per_sample['rawvcf'][sample] += count\n",
    "                else:\n",
    "                    indel_count_per_sample['rawvcf'][sample] = count\n",
    "\n",
    "    for row in read_vcf_line_by_line(vcfwave_path):\n",
    "        samples = list(row.keys())[9:]\n",
    "\n",
    "        ref = row['REF']\n",
    "        alts = row['ALT'].split(',')\n",
    "\n",
    "        for idx, alt in enumerate(alts):\n",
    "            length = len(ref) + len(alt)\n",
    "\n",
    "            IND = False\n",
    "            if (len(ref) <= 1 and len(alt) > 1) or (len(alt) <= 1 and len(ref) > 1):\n",
    "                IND = True\n",
    "\n",
    "            if not IND or length < 50:\n",
    "                continue\n",
    "            entry_counts[2] += 1\n",
    "            for sample in samples:\n",
    "                entry = row[sample]\n",
    "                gt = entry.split(':')[0]\n",
    "                count = len({idx for idx in gt.split('|') if idx not in {'.', '0'}})\n",
    "                assert count <= 2\n",
    "                if 'vcfwave' in indel_count_per_sample and sample in indel_count_per_sample['vcfwave']:\n",
    "                    indel_count_per_sample['vcfwave'][sample] += count\n",
    "                else:\n",
    "                    indel_count_per_sample['vcfwave'][sample] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2926, 4348, 10913]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Sample', \n",
    "                           'Pantree > 50bp INDEL alleles',\n",
    "                           'Raw VCF > 50bp INDEL alleles',\n",
    "                           'Vcfwave > 50bp INDEL alleles'])\n",
    "\n",
    "for sample in sample_list:\n",
    "    df.loc[len(df)] = [sample, \n",
    "     indel_count_per_sample['pantree'][sample], \n",
    "     indel_count_per_sample['rawvcf'][sample], \n",
    "     indel_count_per_sample['vcfwave'][sample]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Pantree &gt; 50bp INDEL alleles</th>\n",
       "      <th>Raw VCF &gt; 50bp INDEL alleles</th>\n",
       "      <th>Vcfwave &gt; 50bp INDEL alleles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHM13</td>\n",
       "      <td>471</td>\n",
       "      <td>2159</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00438</td>\n",
       "      <td>681</td>\n",
       "      <td>3447</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00621</td>\n",
       "      <td>618</td>\n",
       "      <td>3521</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00673</td>\n",
       "      <td>625</td>\n",
       "      <td>3452</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00733</td>\n",
       "      <td>687</td>\n",
       "      <td>3746</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HG00735</td>\n",
       "      <td>630</td>\n",
       "      <td>3566</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HG00741</td>\n",
       "      <td>715</td>\n",
       "      <td>3953</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HG01071</td>\n",
       "      <td>663</td>\n",
       "      <td>3567</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HG01106</td>\n",
       "      <td>671</td>\n",
       "      <td>3566</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HG01109</td>\n",
       "      <td>785</td>\n",
       "      <td>4123</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HG01123</td>\n",
       "      <td>639</td>\n",
       "      <td>3263</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HG01175</td>\n",
       "      <td>660</td>\n",
       "      <td>3479</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HG01243</td>\n",
       "      <td>813</td>\n",
       "      <td>3970</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HG01258</td>\n",
       "      <td>629</td>\n",
       "      <td>3484</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HG01358</td>\n",
       "      <td>671</td>\n",
       "      <td>3564</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HG01361</td>\n",
       "      <td>689</td>\n",
       "      <td>3682</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HG01891</td>\n",
       "      <td>859</td>\n",
       "      <td>4403</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HG01928</td>\n",
       "      <td>605</td>\n",
       "      <td>3448</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HG01952</td>\n",
       "      <td>660</td>\n",
       "      <td>3517</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HG01978</td>\n",
       "      <td>607</td>\n",
       "      <td>3433</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HG02055</td>\n",
       "      <td>741</td>\n",
       "      <td>3703</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HG02080</td>\n",
       "      <td>721</td>\n",
       "      <td>3630</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HG02109</td>\n",
       "      <td>778</td>\n",
       "      <td>3892</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HG02145</td>\n",
       "      <td>780</td>\n",
       "      <td>3948</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HG02148</td>\n",
       "      <td>639</td>\n",
       "      <td>3436</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HG02257</td>\n",
       "      <td>806</td>\n",
       "      <td>4017</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HG02486</td>\n",
       "      <td>806</td>\n",
       "      <td>4080</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HG02559</td>\n",
       "      <td>834</td>\n",
       "      <td>4101</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HG02572</td>\n",
       "      <td>826</td>\n",
       "      <td>3972</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HG02622</td>\n",
       "      <td>791</td>\n",
       "      <td>4330</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HG02630</td>\n",
       "      <td>771</td>\n",
       "      <td>3988</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HG02717</td>\n",
       "      <td>768</td>\n",
       "      <td>4124</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HG02723</td>\n",
       "      <td>744</td>\n",
       "      <td>3827</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HG02818</td>\n",
       "      <td>744</td>\n",
       "      <td>3963</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HG02886</td>\n",
       "      <td>808</td>\n",
       "      <td>4085</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HG03098</td>\n",
       "      <td>823</td>\n",
       "      <td>4099</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HG03453</td>\n",
       "      <td>777</td>\n",
       "      <td>4114</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HG03486</td>\n",
       "      <td>786</td>\n",
       "      <td>4068</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HG03492</td>\n",
       "      <td>684</td>\n",
       "      <td>3681</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HG03516</td>\n",
       "      <td>768</td>\n",
       "      <td>3923</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HG03540</td>\n",
       "      <td>791</td>\n",
       "      <td>3901</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HG03579</td>\n",
       "      <td>820</td>\n",
       "      <td>4277</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NA18906</td>\n",
       "      <td>785</td>\n",
       "      <td>4086</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NA20129</td>\n",
       "      <td>770</td>\n",
       "      <td>3990</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NA21309</td>\n",
       "      <td>785</td>\n",
       "      <td>4027</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample  Pantree > 50bp INDEL alleles  Raw VCF > 50bp INDEL alleles  \\\n",
       "0     CHM13                           471                          2159   \n",
       "1   HG00438                           681                          3447   \n",
       "2   HG00621                           618                          3521   \n",
       "3   HG00673                           625                          3452   \n",
       "4   HG00733                           687                          3746   \n",
       "5   HG00735                           630                          3566   \n",
       "6   HG00741                           715                          3953   \n",
       "7   HG01071                           663                          3567   \n",
       "8   HG01106                           671                          3566   \n",
       "9   HG01109                           785                          4123   \n",
       "10  HG01123                           639                          3263   \n",
       "11  HG01175                           660                          3479   \n",
       "12  HG01243                           813                          3970   \n",
       "13  HG01258                           629                          3484   \n",
       "14  HG01358                           671                          3564   \n",
       "15  HG01361                           689                          3682   \n",
       "16  HG01891                           859                          4403   \n",
       "17  HG01928                           605                          3448   \n",
       "18  HG01952                           660                          3517   \n",
       "19  HG01978                           607                          3433   \n",
       "20  HG02055                           741                          3703   \n",
       "21  HG02080                           721                          3630   \n",
       "22  HG02109                           778                          3892   \n",
       "23  HG02145                           780                          3948   \n",
       "24  HG02148                           639                          3436   \n",
       "25  HG02257                           806                          4017   \n",
       "26  HG02486                           806                          4080   \n",
       "27  HG02559                           834                          4101   \n",
       "28  HG02572                           826                          3972   \n",
       "29  HG02622                           791                          4330   \n",
       "30  HG02630                           771                          3988   \n",
       "31  HG02717                           768                          4124   \n",
       "32  HG02723                           744                          3827   \n",
       "33  HG02818                           744                          3963   \n",
       "34  HG02886                           808                          4085   \n",
       "35  HG03098                           823                          4099   \n",
       "36  HG03453                           777                          4114   \n",
       "37  HG03486                           786                          4068   \n",
       "38  HG03492                           684                          3681   \n",
       "39  HG03516                           768                          3923   \n",
       "40  HG03540                           791                          3901   \n",
       "41  HG03579                           820                          4277   \n",
       "42  NA18906                           785                          4086   \n",
       "43  NA20129                           770                          3990   \n",
       "44  NA21309                           785                          4027   \n",
       "\n",
       "    Vcfwave > 50bp INDEL alleles  \n",
       "0                            423  \n",
       "1                            711  \n",
       "2                            663  \n",
       "3                            660  \n",
       "4                            736  \n",
       "5                            685  \n",
       "6                            771  \n",
       "7                            697  \n",
       "8                            694  \n",
       "9                            836  \n",
       "10                           667  \n",
       "11                           690  \n",
       "12                           863  \n",
       "13                           685  \n",
       "14                           676  \n",
       "15                           722  \n",
       "16                           946  \n",
       "17                           647  \n",
       "18                           678  \n",
       "19                           639  \n",
       "20                           796  \n",
       "21                           779  \n",
       "22                           885  \n",
       "23                           847  \n",
       "24                           635  \n",
       "25                           851  \n",
       "26                           872  \n",
       "27                           875  \n",
       "28                           919  \n",
       "29                           908  \n",
       "30                           880  \n",
       "31                           861  \n",
       "32                           797  \n",
       "33                           827  \n",
       "34                           881  \n",
       "35                           923  \n",
       "36                           876  \n",
       "37                           854  \n",
       "38                           759  \n",
       "39                           833  \n",
       "40                           850  \n",
       "41                           916  \n",
       "42                           856  \n",
       "43                           865  \n",
       "44                           850  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/Data_visualization_v1/distinct_indel_gt_50_count_per_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Level in Snarl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:30<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_level = 0\n",
    "\n",
    "for i in tqdm(chr_list):\n",
    "    ac_df = pd.read_csv(f\"{bubble_summary_dir}/bubble_allele_summary_chr{i}.tsv\", sep='\\t')\n",
    "    for row in ac_df.itertuples(index=False):\n",
    "        level = int(row.Level)\n",
    "        if level > max_level:\n",
    "            max_level = level\n",
    "\n",
    "print(max_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of biallelic (1 variant) and multi-allelic superbubbles (>= 2 variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:39<00:00,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22700968 1923161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "biallelic_count = 0\n",
    "multiallelic_count = 0\n",
    "\n",
    "for chr in tqdm(chr_list):\n",
    "    summary_path = f\"{bubble_summary_dir}/bubble_variant_counts_chr{chr}_AT.tsv\"\n",
    "    AT_csv = pd.read_csv(summary_path, sep='\\t')\n",
    "\n",
    "    biallelic_count += AT_csv['Within_count'].apply(lambda x: x == 1).sum()\n",
    "    multiallelic_count += AT_csv['Within_count'].apply(lambda x: x > 1).sum()\n",
    "\n",
    "print(biallelic_count, multiallelic_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics for triallelic-bubble categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_triallelic_path = f\"{bubble_summary_dir}/bubble_triallelic_all_chr.tsv\"\n",
    "bubble_triallelic_df = pd.read_csv(bubble_triallelic_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bubble_type\n",
       "interlocking           463169\n",
       "overlapping            397291\n",
       "properly_triallelic    133104\n",
       "nested                  43808\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bubble_triallelic_df['Bubble_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 1: median max_allele_length of high allelic superbubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [10:21<00:00, 28.23s/it]\n"
     ]
    }
   ],
   "source": [
    "max_allele_list = []\n",
    "\n",
    "for i in tqdm(range(1,23)):\n",
    "    bubble_allele_summary_path = f\"{bubble_summary_dir}/bubble_allele_summary_chr{i}.tsv\"\n",
    "    bubble_type_path = f\"{bubble_summary_dir}/superbubble_type_chr{i}.tsv\"\n",
    "\n",
    "    bubble_ac_df = pd.read_csv(bubble_allele_summary_path, sep='\\t')\n",
    "    bubble_type_df = pd.read_csv(bubble_type_path, sep='\\t')\n",
    "\n",
    "    filter_bool = bubble_ac_df['Level'].apply(lambda x: int(x) == 0) & bubble_ac_df['num_variants'].apply(lambda x: int(x) >= 10)\n",
    "\n",
    "    bubble_10_more_vars = set(bubble_ac_df['Bubble_id'][filter_bool])\n",
    "    bubble_10_more_vars = set(map(lambda x: tuple(sorted(eval(x), key=lambda y: (len(y), y))), bubble_10_more_vars))\n",
    "    max_allele_list.extend(bubble_type_df['Max_allele_length'][bubble_type_df['Bubble'].apply(lambda x: tuple(sorted(eval(x), key=lambda y: (len(y), y)))).isin(bubble_10_more_vars)].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104160"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_allele_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.median(max_allele_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 2: Details within the high allelic superbubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [24:20<00:00, 66.41s/it]\n"
     ]
    }
   ],
   "source": [
    "high_allelic_superbubble_dict = {}\n",
    "\n",
    "for i in tqdm(range(1,23)):\n",
    "    bubble_ac_path = f\"{bubble_summary_dir}/bubble_allele_summary_chr{i}.tsv\"\n",
    "    bubble_AT_path = f\"{bubble_summary_dir}/bubble_variant_counts_chr{i}_AT.tsv\"\n",
    "    vcf_path = f\"{graph_vcf_dir}/graph_chr{i}_no_terminus.vcf\"\n",
    "\n",
    "    bubble_ac_df = pd.read_csv(bubble_ac_path, sep='\\t')\n",
    "    bubble_ac_dict = {}\n",
    "\n",
    "    for row in bubble_ac_df.itertuples(index=False):\n",
    "        if int(row.Level) != 0: \n",
    "            continue\n",
    "        bubble = tuple(sorted(eval(row.Bubble)))\n",
    "\n",
    "        ac = int(row.raw_vcf_allele_count) if row.raw_vcf_allele_count != '.' else 0\n",
    "\n",
    "        if ac >= 10:\n",
    "            bubble_ac_dict[bubble] = ac\n",
    "\n",
    "    bubble_AT_df = pd.read_csv(bubble_AT_path, sep='\\t')\n",
    "\n",
    "    var_set = set()\n",
    "    bubble_within = {}\n",
    "    for row in bubble_AT_df.itertuples(index=False):\n",
    "        bubble = tuple(sorted(eval(row.Bubble)))\n",
    "        if bubble not in bubble_ac_dict:\n",
    "            continue\n",
    "        var_within = eval(row.Within)\n",
    "        var_set = var_set.union(var_within)\n",
    "        bubble_within[bubble] = var_within\n",
    "\n",
    "    var_dict = {}\n",
    "    for row in read_vcf_line_by_line(vcf_path):\n",
    "        var_id = extract_bubble_ids(row['ID'], symbol=True)\n",
    "        if not var_id in var_set:\n",
    "            continue\n",
    "        info_dict = get_info_dict(row['INFO'])\n",
    "        POS = int(row['POS'])\n",
    "        VT = info_dict['VT']\n",
    "        ref = row['REF'] if row['REF'] != '.' else info_dict['NR']\n",
    "        alt = row['ALT']\n",
    "        allele_length = len(ref) + len(alt)\n",
    "\n",
    "        info_dict.pop('NR')\n",
    "        var_dict[var_id] = (POS, allele_length, info_dict)\n",
    "\n",
    "    for k, v in bubble_within.items():\n",
    "        high_allelic_superbubble_dict[k] = list(map(lambda x: (x, var_dict[x]), v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95632"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_allelic_superbubble_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(range(1,23)):\n",
    "    bubble_AT_path = f\"{bubble_summary_dir}/bubble_variant_counts_chr{i}_AT.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4504608\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for k, v in high_allelic_superbubble_dict.items():\n",
    "    total += len(v)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertion_1kbp = 0\n",
    "deletion_50bp = 0\n",
    "both = 0\n",
    "\n",
    "reference_var = 0\n",
    "reference_var_insertion_1kbp = 0\n",
    "\n",
    "non_reference_var = 0\n",
    "non_reference_var_insertion_1kbp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_with_large_insertion = set()\n",
    "bubble_with_large_deletion = set()\n",
    "\n",
    "for k, v in high_allelic_superbubble_dict.items():\n",
    "    large_var_set = set()\n",
    "    for var_id, var_data in v:\n",
    "        allele_length = var_data[1]\n",
    "        VT = var_data[2]['VT']\n",
    "        DR_v = int(var_data[2]['DR'].split(',')[1])\n",
    "        if DR_v != 0:\n",
    "            non_reference_var += 1\n",
    "        else:\n",
    "            reference_var += 1\n",
    "        if VT == 'INS' and allele_length >= 1000:\n",
    "            large_var_set.add('INS')\n",
    "        if VT == 'DEL' and allele_length >= 50:\n",
    "            large_var_set.add('DEL')\n",
    "    if 'INS' in large_var_set and 'DEL' in large_var_set:\n",
    "        insertion_1kbp += 1\n",
    "        deletion_50bp += 1\n",
    "        both += 1\n",
    "        bubble_with_large_insertion.add(k)\n",
    "        bubble_with_large_deletion.add(k)\n",
    "    elif 'INS' in large_var_set:\n",
    "        insertion_1kbp += 1\n",
    "        bubble_with_large_insertion.add(k)\n",
    "    elif 'DEL' in large_var_set:\n",
    "        deletion_50bp += 1\n",
    "        bubble_with_large_deletion.add(k)\n",
    "\n",
    "for k, v in high_allelic_superbubble_dict.items():\n",
    "    if not k in bubble_with_large_insertion:\n",
    "        continue\n",
    "    for var_id, var_data in v:\n",
    "        allele_length = var_data[1]\n",
    "        VT = var_data[2]['VT']\n",
    "        DR_v = int(var_data[2]['DR'].split(',')[1])\n",
    "        if DR_v != 0:\n",
    "            non_reference_var_insertion_1kbp += 1\n",
    "        else:\n",
    "            reference_var_insertion_1kbp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of superbubbles with >= 1kbp insertion: 2022\n",
      "Number of superbubbles with >= 50bp deletion: 16242\n",
      "Number of superbubbles with both: 1410\n",
      "Number of reference variants: 2216930\n",
      "Number of reference variants in superbubbles with >= 1kbp insertion: 718875\n",
      "Number of non-reference variants: 2287678\n",
      "Number of non-reference variants in superbubbles with >= 1kbp insertion: 1306030\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of superbubbles with >= 1kbp insertion:\", insertion_1kbp)\n",
    "print(\"Number of superbubbles with >= 50bp deletion:\", deletion_50bp)\n",
    "print(\"Number of superbubbles with both:\", both)\n",
    "\n",
    "print(\"Number of reference variants:\", reference_var)\n",
    "print(\"Number of reference variants in superbubbles with >= 1kbp insertion:\", reference_var_insertion_1kbp)\n",
    "\n",
    "print(\"Number of non-reference variants:\", non_reference_var)\n",
    "print(\"Number of non-reference variants in superbubbles with >= 1kbp insertion:\", non_reference_var_insertion_1kbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021143550276058222, 0.3761160829993676)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_1kbp/len(high_allelic_superbubble_dict), non_reference_var_insertion_1kbp/3472412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_linear_var_counts = []\n",
    "\n",
    "for bubble in bubble_with_large_insertion:\n",
    "    off_linear_var_count = 0\n",
    "    vars = high_allelic_superbubble_dict[bubble]\n",
    "    for var in vars:\n",
    "        linear = int(var[1][2]['DR'].split(',')[1]) == 0\n",
    "        if not linear:\n",
    "            off_linear_var_count += 1\n",
    "    off_linear_var_counts.append(off_linear_var_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645.9099901088032"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(off_linear_var_counts)/len(off_linear_var_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-superbubble SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_list = list(range(1,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m bubble_AT_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbubble_summary_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/bubble_variant_counts_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_AT.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m var_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m read_vcf_line_by_line(graph_vcf_path):\n\u001b[1;32m     10\u001b[0m     edge \u001b[38;5;241m=\u001b[39m extract_bubble_ids(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m], symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     info_dict \u001b[38;5;241m=\u001b[39m get_info_dict(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/graph_var/graph_var/evaluating_functions.py:142\u001b[0m, in \u001b[0;36mread_vcf_line_by_line\u001b[0;34m(vcf_path)\u001b[0m\n\u001b[1;32m    140\u001b[0m parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(header), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid VCF format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 142\u001b[0m rec_dict \u001b[38;5;241m=\u001b[39m {header[i]: parts[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(header))}\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m rec_dict\n",
      "File \u001b[0;32m/n/data1/hms/dbmi/oconnor/lab/shz311/pangenome/graph_var/graph_var/evaluating_functions.py:142\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(header), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid VCF format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 142\u001b[0m rec_dict \u001b[38;5;241m=\u001b[39m {header[i]: parts[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(header))}\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m rec_dict\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "non_superbubble_snp_count = [0, 0, 0]\n",
    "\n",
    "for i in tqdm(chr_list):\n",
    "    graph_vcf_path = f\"{graph_vcf_dir}/graph_chr{i}{'_no_terminus' if exclude_terminus else ''}.vcf\"\n",
    "    bubble_AT_path = f\"{bubble_summary_dir}/bubble_variant_counts_chr{i}_AT.tsv\"\n",
    "\n",
    "    var_dict = {}\n",
    "\n",
    "    for row in read_vcf_line_by_line(graph_vcf_path):\n",
    "        edge = extract_bubble_ids(row['ID'], symbol=True)\n",
    "        info_dict = get_info_dict(row['INFO'])\n",
    "        info_dict['POS'] = int(row['POS'])\n",
    "\n",
    "        var_dict[edge] = info_dict\n",
    "    \n",
    "    bubble_AT_df = pd.read_csv(bubble_AT_path, sep='\\t')\n",
    "    bubble_within_dict = {}\n",
    "\n",
    "    for row in bubble_AT_df.itertuples(index=False):\n",
    "        bubble = tuple(sorted(eval(row.Bubble)))\n",
    "\n",
    "        if int(row.Level) == 0:\n",
    "            continue\n",
    "\n",
    "        within = eval(row.Within)\n",
    "\n",
    "        for var in list(within):\n",
    "            if var_dict[var]['VT'] == 'SNP':\n",
    "                non_superbubble_snp_count[0] += 1\n",
    "            \n",
    "            linear = int(var_dict[var]['DR'].split(',')[1]) == 0\n",
    "            if var_dict[var]['VT'] == 'SNP' and linear:\n",
    "                non_superbubble_snp_count[1] += 1\n",
    "            \n",
    "            if var_dict[var]['VT'] == 'SNP' and not linear:\n",
    "                non_superbubble_snp_count[2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([117683, 55228, 62455], 0.5307053695096148)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_superbubble_snp_count, non_superbubble_snp_count[2]/non_superbubble_snp_count[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
